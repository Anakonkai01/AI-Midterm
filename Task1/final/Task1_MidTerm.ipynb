{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Required Libraries\n",
        "\n",
        "- `heapq`: Provides priority queue for A Star Algorithm\n",
        "- `queue`: Provides  queue for Breadth-First Search\n",
        "- `graphviz`: Used for graph visualization, helpful for visualizing data structures.\n",
        "- `uuid`: Generates universally unique identifiers (UUIDs).\n",
        "\n"
      ],
      "metadata": {
        "id": "MIjlpCAJyYsA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJv6Q82nySgF"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "import copy\n",
        "import graphviz as g\n",
        "import uuid\n",
        "import random\n",
        "import queue\n",
        "import math\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Problem**\n",
        "The Problem class represents the task environment for an agent, defining the initial state, goal state(s), and methods to support environment formulation. It includes the following methods:\n",
        "\n",
        "- **GetInitialState (`self`, `initial_state`)**: The starting state of the problem.\n",
        "- **Goal states (`self`, `goal_states`)**: The set of states that satisfy the goal condition.\n",
        "- **isGoalState (`self`, `state`)**: Determines whether a given state is a goal state.\n",
        "- **getSuccessors (`self`, `state`)**: Returns possible next states from the current state.\n",
        "- **getActionCost (`self`, `state`, `action`)**: Returns the cost of taking an action from a state.(For 8-puzzle problem the cost of action is 1)\n"
      ],
      "metadata": {
        "id": "JCkqbIMH5EdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Problem:\n",
        "    def __init__(self, initial_state, goal_states):\n",
        "        self.initial_state = initial_state\n",
        "        self.goal_states = goal_states\n",
        "\n",
        "    def getInitialState(self):\n",
        "        return self.initial_state\n",
        "\n",
        "    def isGoalState(self, state):\n",
        "        return state in self.goal_states\n",
        "\n",
        "    def getSuccessors(self, state):\n",
        "        node = Node(state)\n",
        "        return node.getSuccessors()\n",
        "\n",
        "    def getActionCost(self, state, action):\n",
        "        node = Node.Node(state)\n",
        "        return node.getActionCost()\n",
        "\n",
        "    def get_goal_states(self):\n",
        "        return self.goal_states\n",
        "\n",
        "    def get_initial_state(self):\n",
        "        return self.initial_state"
      ],
      "metadata": {
        "id": "SSgm20xL5E30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**State**\n",
        "\n",
        "The `State` class represents a board configuration in a tile-based puzzle. It includes the following methods:\n",
        "- **GetActions (`self`)**: List of possible actions of the current state.\n",
        "- **GetActionCost (`self`, `state`, `action`)**: Get action cost\n",
        "- **getSuccessor (`self`, `action`)**: Returns the resulting successor after applying the action\n",
        "- **are_adjacent (`getSuccessors`)**, **auto_swap_if_adjacency(`self`)**: Implements logic for swap the tiles if they are in pair (1 and 3 or 2 and 4)\n",
        "\n"
      ],
      "metadata": {
        "id": "Gx_Qykjg5QwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State():\n",
        "    def __init__(self, board):\n",
        "        self.board = board\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self.board == other.board\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(str(self.board))\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(self.board)\n",
        "\n",
        "    def get_board(self):\n",
        "        return self.board\n",
        "\n",
        "    def set_board(self, board):\n",
        "        self.board = board\n",
        "\n",
        "    def get_blank_position(self):\n",
        "        for i in range(len(self.get_board())):\n",
        "            for j in range(len(self.get_board()[0])):\n",
        "                if self.board[i][j] == 0:\n",
        "                    return (i, j)\n",
        "\n",
        "    def swap(self, pos1, pos2):\n",
        "        i1, j1 = pos1\n",
        "        i2, j2 = pos2\n",
        "        self.board[i1][j1], self.board[i2][j2] = self.board[i2][j2], self.board[i1][j1]\n",
        "\n",
        "    '''Get the possible actions of the current state'''\n",
        "    def getActions(self):\n",
        "        actions = []\n",
        "        blank_position = self.get_blank_position()\n",
        "        if blank_position[0] > 0:\n",
        "            actions.append('U')\n",
        "        if blank_position[0] < len(self.get_board()) - 1:\n",
        "            actions.append('D')\n",
        "        if blank_position[1] > 0:\n",
        "            actions.append('L')\n",
        "        if blank_position[1] < len(self.get_board()) - 1:\n",
        "            actions.append('R')\n",
        "        return actions\n",
        "\n",
        "    '''Cost of action is 1'''\n",
        "    def getActionCost(self, state, action):\n",
        "        return 1\n",
        "\n",
        "    '''Return successor with action'''\n",
        "    def getSuccessor(self, action):\n",
        "        blank_position = self.get_blank_position()\n",
        "        new_state = copy.deepcopy(self)\n",
        "\n",
        "        if 'U' == action:\n",
        "            new_state.swap(blank_position, (blank_position[0] - 1, blank_position[1]))\n",
        "        elif 'D' == action:\n",
        "            new_state.swap(blank_position, (blank_position[0] + 1, blank_position[1]))\n",
        "        elif 'L' == action:\n",
        "            new_state.swap(blank_position, (blank_position[0], blank_position[1] - 1))\n",
        "        elif 'R' == action:\n",
        "            new_state.swap(blank_position, (blank_position[0], blank_position[1] + 1))\n",
        "\n",
        "\n",
        "        new_state.auto_swap_if_adjacency()\n",
        "        return new_state\n",
        "\n",
        "\n",
        "    def are_adjacent(self, pos1, pos2):\n",
        "        return abs(pos1[0] - pos2[0]) + abs(pos1[1] - pos2[1]) == 1\n",
        "\n",
        "\n",
        "\n",
        "    def auto_swap_if_adjacency(self):\n",
        "        '''using dictionary to store position of each number in the board'''\n",
        "        position = {}\n",
        "        for i in range(len(self.get_board())):\n",
        "            for j in range(len(self.get_board()[0])):\n",
        "                position[self.board[i][j]] = (i, j)\n",
        "\n",
        "        ''' swap if cell 1 and cell 3 are adjacent'''\n",
        "        if self.are_adjacent(position[1], position[3]):\n",
        "            self.swap(position[1], position[3])\n",
        "\n",
        "        '''swap if cell 2 and cell 4 are adjacent'''\n",
        "        if self.are_adjacent(position[2], position[4]):\n",
        "            self.swap(position[2], position[4])\n"
      ],
      "metadata": {
        "id": "RO6_byQ75RD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Node**\n",
        "\n",
        "The `Node` class represents a state in the search tree. Each node stores information about the state, the action taken to reach it, its parent, and heuristic values used for informed search algorithms like A*.It includes the following methods:\n",
        "\n",
        "- **__str__(`self`)**: Returns a string representation of the board, including `G` and `H` values.\n",
        "- **__lt__(`self`, `other`)**: Compares two nodes based on their `f(x) = G + H` value for A* search.\n",
        "- **get_id(`self`)**: Generates a unique ID for visualization based on the state's hash.\n",
        "- **getSuccessors(`self`)**: Generates and returns a list of successor nodes by applying all possible actions.\n",
        "- **draw(`self`, `dot`, `color='black'`, `drawn_edges=None`)**: Visualizes the node in a graph structure using Graphviz, drawing edges to its `parent`.\n",
        "\n"
      ],
      "metadata": {
        "id": "9SBgFPh1z7yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, state, action = None, parent = None, G =None, H=None):\n",
        "        self.state = state\n",
        "        self.action = action\n",
        "        self.parent = parent\n",
        "        self.G = G\n",
        "        self.H = H\n",
        "        self.ID = str(self)\n",
        "\n",
        "    ''''''\n",
        "    def __str__(self):\n",
        "        board_str = '\\n'.join(''.join(str(num) if num != 0 else '_' for num in row) for row in self.get_state().get_board())\n",
        "        return f\"{board_str}\\n g_value:{self.get_G()}\\n h_value: {self.H}\"\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        \"\"\" Compare the f_x for AStar \"\"\"\n",
        "        return (self.G + self.H) < (other.G + other.H)\n",
        "    def get_state(self):\n",
        "        return self.state\n",
        "\n",
        "    def get_action(self):\n",
        "        return self.action\n",
        "\n",
        "    def get_G(self):\n",
        "        return self.G\n",
        "\n",
        "    def set_G(self, G):\n",
        "        self.G = G\n",
        "\n",
        "    def get_parent(self):\n",
        "        return self.parent\n",
        "\n",
        "    def get_id(self):\n",
        "        \"\"\" Dùng ID cố định dựa trên state để vẽ đồ thị \"\"\"\n",
        "        return str(hash(str(self.state)))\n",
        "\n",
        "    #For visualize the result\n",
        "    def get_str_node(self):\n",
        "        return str(self)\n",
        "\n",
        "    def getActionCost(self):\n",
        "        return 1\n",
        "\n",
        "    def set_H(self, H):\n",
        "        self.H = H\n",
        "\n",
        "    def get_H(self):\n",
        "        return self.H\n",
        "\n",
        "    def set_parent(self, parent):\n",
        "        self.parent = parent\n",
        "\n",
        "    #Get all successors of a node\n",
        "    def getSuccessors(self):\n",
        "        successors = []\n",
        "        state_of_node = self.get_state()\n",
        "        for action in state_of_node.getActions():\n",
        "            new_state = state_of_node.getSuccessor(action)\n",
        "            cost = new_state.getActionCost(state_of_node, action)\n",
        "            successors.append(Node(new_state, action, self, cost))\n",
        "        return successors\n",
        "\n",
        "    ''''''\n",
        "    def draw(self, dot, color='black', drawn_edges=None):\n",
        "        dot.node(self.get_id(), self.get_str_node(), shape=\"square\", color=color)\n",
        "        if self.get_parent() is not None:\n",
        "            dot.edge(self.get_parent().get_id(), self.get_id(), label=self.get_action(), color=color)\n"
      ],
      "metadata": {
        "id": "NttNxHmsz8HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heuristic\n",
        "\n",
        "- `Num_linear_conflict(current_board, goal_board)`: Counts linear conflicts (tiles blocking each other) in rows and columns.\n",
        "- `EnhancedManhattan(state, goalStates)`: Computes Manhattan distance plus a conflict penalty for more accurate heuristics.\n",
        "- `getHeuristic(state, goalStates)`: Calls the selected heuristic function (`EnhancedManhattan` or `EnhancedMissplace`).\n"
      ],
      "metadata": {
        "id": "zfPh9C1VzSJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Heuristic:\n",
        "    def __init__(self, type):\n",
        "        self.heuristic_type = type\n",
        "        self.Heuristics =    {\n",
        "                                \"EnhancedManhattan\": self.EnhancedManhattan,\n",
        "                                \"EnhancedMissPlace\": self.EnhancedMissplace,\n",
        "                                \"PatternDataBase\": self.PatternDataBase,\n",
        "                             }\n",
        "        self.heuristic_func = self.Heuristics[self.heuristic_type]\n",
        "        '''For PaternDatabse Heuristic'''\n",
        "        self.pdbList = []\n",
        "\n",
        "    '''Conflict: Number of tile pairs in which one tile prevent other from reaching the goal position'''\n",
        "    @staticmethod\n",
        "    def Num_linear_conflict(current_board, goal_board):\n",
        "        number_of_conflicts = 0\n",
        "\n",
        "        '''Look-up table for permutation can cause the conflict'''\n",
        "        look_up_conflict = lambda a,b,c: [[b,a,c], [c,b,a], [a,c,b]]\n",
        "\n",
        "        ''' Caculate number of confilcts in rows'''\n",
        "        for row in range(len(current_board)):\n",
        "            current_row = current_board[row]\n",
        "            goal_row = goal_board[row]\n",
        "            a,b,c = goal_row[0], goal_row[1], goal_row[2]\n",
        "            potential_conflict_rows = look_up_conflict(a,b,c)\n",
        "            if current_row in potential_conflict_rows:\n",
        "                if current_row == potential_conflict_rows[1]:\n",
        "                    number_of_conflicts += 2\n",
        "                    continue\n",
        "                number_of_conflicts += 1\n",
        "\n",
        "        ''' Caculate the number of conflict in columns'''\n",
        "        for col in range(len(current_board)):\n",
        "            current_row = [current_board[row][col] for row in range(len(current_board))]\n",
        "            goal_row= [goal_board[row][col] for row in range(len(goal_board))]\n",
        "            a,b,c = goal_row[0], goal_row[1], goal_row[2]\n",
        "            potential_conflict_rows = look_up_conflict(a,b,c)\n",
        "            if current_row in potential_conflict_rows:\n",
        "                if current_row == potential_conflict_rows[1]:\n",
        "                    number_of_conflicts += 2\n",
        "                    continue\n",
        "                number_of_conflicts += 1\n",
        "        return number_of_conflicts\n",
        "\n",
        "    '''A heuristic that combines the traditional Manhattan distance with the number of conflicts\n",
        "    (Clarifies cases where two states have the same Manhattan distance but different tile positions in a row or column).'''\n",
        "    def EnhancedManhattan(self, state, goalStates):\n",
        "      list_distance = []\n",
        "      for goal in goalStates:\n",
        "\n",
        "          board_goal = goal.get_board()\n",
        "          goal_pos = {board_goal[i][j]: (i, j) for i in range(len(board_goal)) for j in range(len(board_goal))}\n",
        "\n",
        "\n",
        "          distance = 0\n",
        "          board_state = state.get_board()\n",
        "          for i in range(len(board_state)):\n",
        "              for j in range(len(board_state)):\n",
        "                  tile = board_state[i][j]\n",
        "                  if tile != 0:\n",
        "                      gx, gy = goal_pos[tile]\n",
        "                      distance += abs(gx - i) + abs(gy - j)\n",
        "\n",
        "\n",
        "          conflict = Heuristic.Num_linear_conflict(board_state, board_goal)\n",
        "          list_distance.append(distance + 2 * conflict)\n",
        "      return min(list_distance)\n",
        "\n",
        "    @staticmethod\n",
        "    def EnhancedManhattanWithAGoal( state, goalState):\n",
        "        # Lấy bảng đích\n",
        "        board_goal = goalState.get_board()\n",
        "        goal_pos = {board_goal[i][j]: (i, j) for i in range(len(board_goal)) for j in range(len(board_goal))}\n",
        "\n",
        "        # Tính Manhattan\n",
        "        distance = 0\n",
        "        board_state = state.get_board()\n",
        "        for i in range(len(board_state)):\n",
        "            for j in range(len(board_state)):\n",
        "                tile = board_state[i][j]\n",
        "                if tile != 0:\n",
        "                    gx, gy = goal_pos[tile]\n",
        "                    distance += abs(gx - i) + abs(gy - j)\n",
        "\n",
        "        # Tính số conflict với goal hiện tại\n",
        "        conflict = Heuristic.Num_linear_conflict(board_state, board_goal)\n",
        "\n",
        "        # Trả về tổng Manhattan và conflict\n",
        "        return distance + 2 * conflict\n",
        "\n",
        "    def EnhancedMissplace(self, state, goalStates):\n",
        "        min_misplaced = 9\n",
        "        for goalState in goalStates:\n",
        "            misplaced = 0\n",
        "            board_state = state.get_board()\n",
        "            board_goal = goalState.get_board()\n",
        "\n",
        "\n",
        "            for i in range(len(board_state)):\n",
        "                for j in range(len(board_state)):\n",
        "                    if board_state[i][j] != board_goal[i][j]:\n",
        "                        misplaced += 1\n",
        "\n",
        "\n",
        "            conflict = Heuristic.Num_linear_conflict(board_state, board_goal)\n",
        "            min_misplaced = min(min_misplaced, misplaced + 2 * conflict)\n",
        "\n",
        "        return min_misplaced\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Procedure BUILD_FOUR_PDBS(goals[4]):\n",
        "#     pdb_list ← ∅\n",
        "#     For each goal g in goals:\n",
        "#         pdb_g ← BUILD_PDB_FROM_GOAL(g)      // BFS để xây PDB cho goal g\n",
        "#         pdb_list.add(pdb_g)\n",
        "#     return pdb_list\n",
        "\n",
        "# Procedure BUILD_PDB_FROM_GOAL(goal):\n",
        "#     Initialize an empty map pdb           // pdb[state] = cost ngắn nhất từ state đến goal\n",
        "#     Create a queue Q\n",
        "#     pdb[goal] ← 0\n",
        "#     Enqueue(goal, Q)\n",
        "#     while Q is not empty:\n",
        "#         current ← Dequeue(Q)\n",
        "#         current_cost ← pdb[current]\n",
        "#         successors ← GET_SUCCESSORS(current)  // sinh tất cả successor (có auto swap)\n",
        "#         for each (succ, stepCost) in successors:\n",
        "#             if succ not in pdb:\n",
        "#                 pdb[succ] ← current_cost + stepCost\n",
        "#                 Enqueue(succ, Q)\n",
        "#     return pdb\n",
        "\n",
        "    def PatternDataBase(self, state, goalStates):\n",
        "        \"\"\"\n",
        "        Hàm được gọi mỗi lần cần tính heuristic PDB cho 'state'.\n",
        "        Ta đã có self.pdbList = [pdb_goal1, pdb_goal2, pdb_goal3, pdb_goal4]\n",
        "        Mỗi pdb_goalX là dict: { state_tupla -> cost }.\n",
        "\n",
        "        => Tính cost = min( pdb_goalX.get(state_tupla, infinity) )\n",
        "        \"\"\"\n",
        "        if not self.pdbList:\n",
        "            # Nếu chưa build, trả về 0 hoặc Infinity tuỳ\n",
        "            return 0\n",
        "        state_key = tuple(num for row in state.get_board() for num in row)\n",
        "        best_cost = math.inf\n",
        "        for pdb_dict in self.pdbList:\n",
        "            cost = pdb_dict.get(state_key, math.inf)\n",
        "            if cost < best_cost:\n",
        "                best_cost = cost\n",
        "        return best_cost\n",
        "\n",
        "    def PatternDataBaseBuildAll(self, goalStates):\n",
        "        \"\"\"\n",
        "        Xây 4 PDB, mỗi PDB_i ứng với goalStates[i].\n",
        "        Trả về list 4 dict.\n",
        "        \"\"\"\n",
        "        pdb_list = []\n",
        "        for goal in goalStates:\n",
        "            pdb_g = self.buildPDBFromGoal(goal)\n",
        "            pdb_list.append(pdb_g)\n",
        "        return pdb_list\n",
        "\n",
        "    def buildPDBFromGoal(self, goal):\n",
        "        \"\"\"\n",
        "        BFS từ goal, duyệt toàn bộ state reachable (theo quy tắc di chuyển + auto swap),\n",
        "        ghi pdb[state_tuple] = cost từ state -> goal.\n",
        "        \"\"\"\n",
        "        pdb = {}\n",
        "        Q = queue.Queue()\n",
        "\n",
        "        # Chuyển goal thành key (tuple)\n",
        "        goal_key = tuple(num for row in goal.get_board() for num in row)\n",
        "\n",
        "        pdb[goal_key] = 0\n",
        "        Q.put(goal)\n",
        "\n",
        "        while not Q.empty():\n",
        "            current_state = Q.get()\n",
        "            current_cost_key = tuple(num for row in current_state.get_board() for num in row)\n",
        "            current_cost = pdb[current_cost_key]\n",
        "\n",
        "            current_node = Node(current_state)\n",
        "            for successor in current_node.getSuccessors():\n",
        "                succ_key = tuple(num for row in successor.get_state().get_board() for num in row)\n",
        "                if succ_key not in pdb:\n",
        "                    pdb[succ_key] = current_cost + successor.getActionCost()\n",
        "                    Q.put(successor.get_state())\n",
        "\n",
        "        return pdb\n",
        "    def getHeuristic(self, state, goalStates):\n",
        "        return self.heuristic_func(state, goalStates)"
      ],
      "metadata": {
        "id": "iTHLkXNuzMrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "import pickle\n",
        "\n",
        "H = Heuristic(\"PatternDataBase\")\n",
        "goal_states = []\n",
        "goal_states.append(State([[1, 2, 3], [4, 5, 6], [7, 8, 0]]))\n",
        "goal_states.append(State([[8, 7, 6], [5, 4, 3], [2, 1, 0]]))\n",
        "goal_states.append(State([[0, 1, 2], [3, 4, 5], [6, 7, 8]]))\n",
        "goal_states.append(State([[0, 8, 7], [6, 5, 4], [3, 2, 1]]))\n",
        "\n",
        "H.PatternDataBaseBuildAll(goal_states)\n",
        "\n",
        "i=1\n",
        "for goal in H.pdbList:\n",
        "  with open(f'DatabaseForGoal{i}.pkl', 'rb') as f:\n",
        "    pickle.dump(f)\n",
        "    files.download(f'DatabaseForGoal{i}.pkl')\n",
        "\n"
      ],
      "metadata": {
        "id": "tvwbrj-DB2kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Search**  \n",
        "Implements the **A* search algorithm** with heuristic evaluation and optional visualization. It includes the following methods:\n",
        "\n",
        "- **AStar(`problem`)**: Performs **A* search** to find an optimal path from `problem`'s initial state to a goal state.  \n",
        "  Expands nodes using `f(x) = G + H` and maintains a priority queue.  \n",
        "  Returns the solution path and the number of expanded nodes.  \n",
        "\n",
        "- **getPath(`node`)**: Reconstructs the solution path by tracing back from `node` to the initial state.  \n",
        "\n",
        "- **Visual(`numberNodesDraw`)**: Visualizes the search process using Graphviz, displaying up to `numberNodesDraw` nodes.  \n"
      ],
      "metadata": {
        "id": "tL7asqC05Grq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Search:\n",
        "    def __init__(self,heuristic: Heuristic, numberNodesDraw = None):\n",
        "        self.heuristic = heuristic\n",
        "        self.graph = None\n",
        "        self.numberNodesDraw = numberNodesDraw if numberNodesDraw is not None else 0\n",
        "        self.uniqueId = str(uuid.uuid4())[:8] #Id for visual graph\n",
        "\n",
        "    '''Graph Search AStar Algorithm '''\n",
        "    def AStar(self, problem):\n",
        "        if self.numberNodesDraw:\n",
        "            self.graph = self.graph = g.Digraph(name=f\"Graph_{self.uniqueId}\")\n",
        "        expandedNodes = 0\n",
        "\n",
        "        initial_state = problem.get_initial_state()\n",
        "        if problem.isGoalState(initial_state):\n",
        "            return [], expandedNodes\n",
        "\n",
        "        initial_H  = self.heuristic.heuristic_func(initial_state, problem.get_goal_states())\n",
        "        initial_node = Node(initial_state, H= initial_H, G = 0)\n",
        "\n",
        "        frontier = []\n",
        "        heapq.heappush(frontier, (0, initial_node))\n",
        "\n",
        "        costSoFar = {initial_node.get_state() : 0}\n",
        "        #explored = set()\n",
        "\n",
        "        while frontier:\n",
        "            g_value, node = heapq.heappop(frontier)\n",
        "            expandedNodes += 1\n",
        "\n",
        "\n",
        "            '''Only draw nodes up to the allowed limit; the algorithm still runs normally.'''\n",
        "            if self.numberNodesDraw is not None and expandedNodes <= self.numberNodesDraw:\n",
        "                node.draw(self.graph)\n",
        "\n",
        "            if problem.isGoalState(node.get_state()):\n",
        "                return self.getPath(node), expandedNodes\n",
        "\n",
        "            for successor in node.getSuccessors():\n",
        "                stateOfSuccessor = successor.get_state()\n",
        "                g_value = node.get_G() + successor.getActionCost()\n",
        "                h_value = self.heuristic.heuristic_func(stateOfSuccessor, problem.get_goal_states())\n",
        "\n",
        "\n",
        "                '''No need to compute f(x) = g(x) + h(x) explicitly as __lt__ is defined in Node.'''\n",
        "                if stateOfSuccessor not in costSoFar or g_value < costSoFar[stateOfSuccessor]:\n",
        "                    costSoFar[stateOfSuccessor] = g_value\n",
        "                    successor.set_G(g_value)\n",
        "                    successor.set_H(h_value)\n",
        "                    successor.set_parent(node)\n",
        "                    heapq.heappush(frontier, (g_value, successor))\n",
        "\n",
        "        return None, None\n",
        "\n",
        "\n",
        "    def getPath(self, node):\n",
        "        path = []\n",
        "        while node:\n",
        "            path.append(node)\n",
        "            if isinstance(node, Node):\n",
        "                node = node.get_parent()\n",
        "        return path[::-1]\n",
        "\n",
        "    '''Visualize the AStar Algorithm'''\n",
        "    def Visual(self, numberNodesDraw, problem):\n",
        "        self.numberNodesDraw = numberNodesDraw\n",
        "        path_nodes,_ = self.AStar(problem)\n",
        "        display(g.Source(self.graph.source))\n"
      ],
      "metadata": {
        "id": "lz4kPhAU5G4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xDrTqrDt_XOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BFS():\n",
        "  def BFS(self, problem: Problem):\n",
        "      expandedNodes = 0\n",
        "      initial_state = problem.get_initial_state()\n",
        "      if problem.isGoalState(initial_state):\n",
        "          return [], expandedNodes\n",
        "\n",
        "      initial_node = Node(initial_state, G=0)\n",
        "      frontier = []\n",
        "      frontier.append(initial_node)\n",
        "      explored = set()\n",
        "\n",
        "      while frontier:\n",
        "          node = frontier.pop(0)\n",
        "          expandedNodes += 1\n",
        "\n",
        "          if problem.isGoalState(node.get_state()):\n",
        "              return self.getPath(node), expandedNodes\n",
        "\n",
        "          for successor in node.getSuccessors():\n",
        "              stateOfSuccessor = successor.get_state()\n",
        "              if stateOfSuccessor not in explored:\n",
        "                  explored.add(stateOfSuccessor)\n",
        "                  successor.set_parent(node)\n",
        "                  frontier.append(successor)\n",
        "      return None\n",
        "\n",
        "  def getPath(self, node):\n",
        "    path = []\n",
        "    while node:\n",
        "        path.append(node)\n",
        "        if isinstance(node, Node):\n",
        "            node = node.get_parent()\n",
        "    return path[::-1]"
      ],
      "metadata": {
        "id": "-b9dkcOl_Wsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Demo"
      ],
      "metadata": {
        "id": "qPG0Uu-E6Cxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Demo:\n",
        "    def __init__(self, heuristic_choice, mode_choice, numberNodesDraw=None ):\n",
        "        # heuristic_choice: '1' cho EnhancedManhattan, '2' cho EnhancedMissPlace\n",
        "        # mode_choice: '1' để chạy mô phỏng có vẽ, '2' để chỉ trả kết quả đánh giá\n",
        "        if heuristic_choice == '1':\n",
        "            self.heuristic_type = \"EnhancedManhattan\"\n",
        "        elif heuristic_choice == '2':\n",
        "            self.heuristic_type = \"EnhancedMissPlace\"\n",
        "        elif heuristic_choice == '3':\n",
        "            self.heuristic_type = \"PatternDataBase\"\n",
        "        else:\n",
        "            raise ValueError(\"Lựa chọn heuristic không hợp lệ. Vui lòng chọn 1 hoặc 2.\")\n",
        "\n",
        "        self.mode_choice = mode_choice\n",
        "\n",
        "        # Tạo trạng thái ban đầu\n",
        "        self.initial_state = self.generate_random_state()\n",
        "\n",
        "        # Thiết lập các trạng thái mục tiêu\n",
        "        self.goal_states = []\n",
        "        self.goal_states.append(State([[1, 2, 3], [4, 5, 6], [7, 8, 0]]))\n",
        "        self.goal_states.append(State([[8, 7, 6], [5, 4, 3], [2, 1, 0]]))\n",
        "        self.goal_states.append(State([[0, 1, 2], [3, 4, 5], [6, 7, 8]]))\n",
        "        self.goal_states.append(State([[0, 8, 7], [6, 5, 4], [3, 2, 1]]))\n",
        "\n",
        "        # Tạo bài toán\n",
        "        self.problem = Problem(self.initial_state, self.goal_states)\n",
        "\n",
        "        # Tạo đối tượng tìm kiếm với heuristic đã chọn và số node cần vẽ (nếu có)\n",
        "        self.search_algo = Search(Heuristic(self.heuristic_type), numberNodesDraw)\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_random_state():\n",
        "        numbers = list(range(9))\n",
        "        random.seed(42)\n",
        "        random.shuffle(numbers)\n",
        "        board = [numbers[i:i+3] for i in range(0, 9, 3)]\n",
        "        return State(board)\n",
        "\n",
        "    def run(self):\n",
        "        if self.mode_choice == '1':\n",
        "            self.run_simulation()\n",
        "        elif self.mode_choice == '2':\n",
        "            self.run_evaluation()\n",
        "        else:\n",
        "            print(\"Lựa chọn chế độ không hợp lệ.\")\n",
        "\n",
        "    def run_simulation(self):\n",
        "        # Chạy tìm kiếm A* và mô phỏng (với đồ thị)\n",
        "        path, expanded_nodes = self.search_algo.AStar(self.problem)\n",
        "        print(\"=== A* Search Simulation ===\")\n",
        "        print(\"Initial State:\", self.initial_state.get_board())\n",
        "        for i, node in enumerate(path, start=1):\n",
        "            print(f\"Step {i}: {node.get_state().get_board()}\")\n",
        "        print(\"Total cost:\", len(path))\n",
        "        print(\"Số node mở rộng:\", expanded_nodes)\n",
        "        # Vẽ đồ thị với số node cần vẽ (giá trị đã thiết lập)\n",
        "        self.search_algo.Visual(self.search_algo.numberNodesDraw,self.problem)\n",
        "\n",
        "    def run_evaluation(self):\n",
        "     # Đánh giá Pattern Database heuristic (nếu được chọn)\n",
        "        if self.heuristic_type == \"PatternDataBase\":\n",
        "            # 1. Build Pattern Database trước khi chạy A*\n",
        "            self.search_algo.heuristic.pdbList = self.search_algo.heuristic.PatternDataBaseBuildAll(self.problem.get_goal_states())\n",
        "\n",
        "            # 2. Chạy A* với PDB heuristic\n",
        "            path_pdb, expanded_pdb = self.search_algo.AStar(self.problem)\n",
        "            print(\"Pattern Database Heuristic Search:\")\n",
        "            print(\"Initial State:\", self.initial_state.get_board())\n",
        "            for i, node in enumerate(path_pdb, start=1):\n",
        "                h_value = self.search_algo.heuristic.PatternDataBase(node.get_state(), self.problem.get_goal_states()) # Sử dụng hàm PDB heuristic đã build\n",
        "                print(f\"Step {i}: {node.get_state().get_board()}, H_value: {h_value}\")\n",
        "            print(\"Total cost (Pattern Database):\", len(path_pdb))\n",
        "            print(\"Số node mở rộng (Pattern Database):\", expanded_pdb)\n",
        "            print(\"\\n-----------------------------\\n\")\n",
        "        # Đánh giá A* search\n",
        "        astar_search = Search(Heuristic(self.heuristic_type))\n",
        "        path_astar, expanded_astar = astar_search.AStar(self.problem)\n",
        "        print(\"A* Search:\")\n",
        "        print(\"Initial State:\", self.initial_state.get_board())\n",
        "        for i, node in enumerate(path_astar, start=1):\n",
        "            h_value = Heuristic.EnhancedManhattanWithAGoal(node.get_state(), path_astar[-1].get_state())\n",
        "            print(f\"Step {i}: {node.get_state().get_board()}, H_value: {h_value}\")\n",
        "        print(\"Total cost (A*):\", len(path_astar))\n",
        "        print(\"Số node mở rộng (A*):\", expanded_astar)\n",
        "        print(\"\\n-----------------------------\\n\")\n",
        "        # Đánh giá BFS search\n",
        "        bfs_search = BFS()\n",
        "        path_bfs, expanded_bfs = bfs_search.BFS(self.problem)\n",
        "        print(\"BFS Search:\")\n",
        "        print(\"Initial State:\", self.initial_state.get_board())\n",
        "        for i, node in enumerate(path_bfs, start=1):\n",
        "            print(f\"Step {i}: {node.get_state().get_board()}\")\n",
        "        print(\"Total cost (BFS):\", len(path_bfs))\n",
        "        print(\"Số node mở rộng (BFS):\", expanded_bfs)\n",
        "\n",
        "# -------------------------------\n",
        "# Giao diện chính (Main)\n",
        "# -------------------------------\n",
        "\n",
        "def main():\n",
        "\n",
        "    print(\"Chọn ví dụ cho Heuristic:\")\n",
        "    print(\"1: EnhancedManhattan\")\n",
        "    print(\"2: EnhancedMissPlace\")\n",
        "    print(\"3: PatternDataBase\")\n",
        "    heuristic_choice = input(\"Nhập lựa chọn (1, 2 hoặc 3): \").strip()\n",
        "\n",
        "    print(\"\\nChọn chế độ:\")\n",
        "    print(\"1: Chạy mô phỏng (có vẽ mô phỏng)\")\n",
        "    print(\"2: Chỉ trả đánh giá kết quả\")\n",
        "    mode_choice = input(\"Nhập lựa chọn (1 hoặc 2): \").strip()\n",
        "    print(\"Chọn số testcase: \")\n",
        "    n = input(\"Nhập số testcase (số nguyên): \").strip()\n",
        "\n",
        "    numberNodesDraw = 0\n",
        "    if mode_choice == '1':\n",
        "        # Yêu cầu người dùng nhập số node muốn vẽ (nếu có)\n",
        "        try:\n",
        "            numberNodesDraw = int(input(\"Nhập số node muốn vẽ (số nguyên): \").strip())\n",
        "        except ValueError:\n",
        "            numberNodesDraw = 0\n",
        "\n",
        "    try:\n",
        "        for i in range(int(n)):\n",
        "            print(f\"\\nTest case {i+1}:\")\n",
        "            demo = Demo(heuristic_choice, mode_choice, numberNodesDraw)\n",
        "            demo.run()\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx61j95C6DDb",
        "outputId": "f3b8ffe5-7f45-4e64-ac09-8ed2828c5e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chọn ví dụ cho Heuristic:\n",
            "1: EnhancedManhattan\n",
            "2: EnhancedMissPlace\n",
            "3: PatternDataBase\n",
            "Nhập lựa chọn (1, 2 hoặc 3): 3\n",
            "\n",
            "Chọn chế độ:\n",
            "1: Chạy mô phỏng (có vẽ mô phỏng)\n",
            "2: Chỉ trả đánh giá kết quả\n",
            "Nhập lựa chọn (1 hoặc 2): 2\n",
            "Chọn số testcase: \n",
            "Nhập số testcase (số nguyên): 2\n",
            "\n",
            "Test case 1:\n",
            "Pattern Database Heuristic Search:\n",
            "Initial State: [[3, 6, 7], [4, 8, 2], [5, 0, 1]]\n",
            "Step 1: [[3, 6, 7], [4, 8, 2], [5, 0, 1]], H_value: 13\n",
            "Step 2: [[3, 6, 7], [4, 0, 2], [5, 8, 1]], H_value: 12\n",
            "Step 3: [[3, 6, 7], [2, 4, 0], [5, 8, 1]], H_value: 13\n",
            "Step 4: [[3, 6, 7], [2, 0, 4], [5, 8, 1]], H_value: 10\n",
            "Step 5: [[3, 6, 7], [2, 8, 4], [5, 0, 1]], H_value: 9\n",
            "Step 6: [[3, 6, 7], [2, 8, 4], [0, 5, 1]], H_value: 8\n",
            "Step 7: [[3, 6, 7], [0, 8, 4], [2, 5, 1]], H_value: 7\n",
            "Step 8: [[0, 6, 7], [3, 8, 4], [2, 5, 1]], H_value: 6\n",
            "Step 9: [[6, 0, 7], [3, 8, 4], [2, 5, 1]], H_value: 5\n",
            "Step 10: [[6, 8, 7], [3, 0, 4], [2, 5, 1]], H_value: 4\n",
            "Step 11: [[6, 8, 7], [3, 5, 4], [2, 0, 1]], H_value: 3\n",
            "Step 12: [[6, 8, 7], [3, 5, 4], [0, 2, 1]], H_value: 2\n",
            "Step 13: [[6, 8, 7], [0, 5, 4], [3, 2, 1]], H_value: 1\n",
            "Step 14: [[0, 8, 7], [6, 5, 4], [3, 2, 1]], H_value: 0\n",
            "Total cost (Pattern Database): 14\n",
            "Số node mở rộng (Pattern Database): 2959\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "A* Search:\n",
            "Initial State: [[3, 6, 7], [4, 8, 2], [5, 0, 1]]\n",
            "Step 1: [[3, 6, 7], [4, 8, 2], [5, 0, 1]], H_value: 11\n",
            "Step 2: [[3, 6, 7], [4, 0, 2], [5, 8, 1]], H_value: 12\n",
            "Step 3: [[3, 6, 7], [0, 2, 4], [5, 8, 1]], H_value: 9\n",
            "Step 4: [[3, 6, 7], [2, 0, 4], [5, 8, 1]], H_value: 10\n",
            "Step 5: [[3, 6, 7], [2, 8, 4], [5, 0, 1]], H_value: 9\n",
            "Step 6: [[3, 6, 7], [2, 8, 4], [0, 5, 1]], H_value: 8\n",
            "Step 7: [[3, 6, 7], [0, 8, 4], [2, 5, 1]], H_value: 7\n",
            "Step 8: [[0, 6, 7], [3, 8, 4], [2, 5, 1]], H_value: 6\n",
            "Step 9: [[6, 0, 7], [3, 8, 4], [2, 5, 1]], H_value: 5\n",
            "Step 10: [[6, 8, 7], [3, 0, 4], [2, 5, 1]], H_value: 4\n",
            "Step 11: [[6, 8, 7], [3, 5, 4], [2, 0, 1]], H_value: 3\n",
            "Step 12: [[6, 8, 7], [3, 5, 4], [0, 2, 1]], H_value: 2\n",
            "Step 13: [[6, 8, 7], [0, 5, 4], [3, 2, 1]], H_value: 3\n",
            "Step 14: [[0, 8, 7], [6, 5, 4], [3, 2, 1]], H_value: 0\n",
            "Total cost (A*): 14\n",
            "Số node mở rộng (A*): 4441\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "BFS Search:\n",
            "Initial State: [[3, 6, 7], [4, 8, 2], [5, 0, 1]]\n",
            "Step 1: [[3, 6, 7], [4, 8, 2], [5, 0, 1]]\n",
            "Step 2: [[3, 6, 7], [4, 0, 2], [5, 8, 1]]\n",
            "Step 3: [[3, 6, 7], [0, 2, 4], [5, 8, 1]]\n",
            "Step 4: [[3, 6, 7], [2, 0, 4], [5, 8, 1]]\n",
            "Step 5: [[3, 6, 7], [2, 8, 4], [5, 0, 1]]\n",
            "Step 6: [[3, 6, 7], [2, 8, 4], [0, 5, 1]]\n",
            "Step 7: [[3, 6, 7], [0, 8, 4], [2, 5, 1]]\n",
            "Step 8: [[0, 6, 7], [3, 8, 4], [2, 5, 1]]\n",
            "Step 9: [[6, 0, 7], [3, 8, 4], [2, 5, 1]]\n",
            "Step 10: [[6, 8, 7], [3, 0, 4], [2, 5, 1]]\n",
            "Step 11: [[6, 8, 7], [3, 5, 4], [2, 0, 1]]\n",
            "Step 12: [[6, 8, 7], [3, 5, 4], [0, 2, 1]]\n",
            "Step 13: [[6, 8, 7], [0, 5, 4], [3, 2, 1]]\n",
            "Step 14: [[0, 8, 7], [6, 5, 4], [3, 2, 1]]\n",
            "Total cost (BFS): 14\n",
            "Số node mở rộng (BFS): 3742\n",
            "\n",
            "Test case 2:\n",
            "Pattern Database Heuristic Search:\n",
            "Initial State: [[3, 6, 7], [4, 8, 2], [5, 0, 1]]\n",
            "Step 1: [[3, 6, 7], [4, 8, 2], [5, 0, 1]], H_value: 13\n",
            "Step 2: [[3, 6, 7], [4, 0, 2], [5, 8, 1]], H_value: 12\n",
            "Step 3: [[3, 6, 7], [2, 4, 0], [5, 8, 1]], H_value: 13\n",
            "Step 4: [[3, 6, 7], [2, 0, 4], [5, 8, 1]], H_value: 10\n",
            "Step 5: [[3, 6, 7], [2, 8, 4], [5, 0, 1]], H_value: 9\n",
            "Step 6: [[3, 6, 7], [2, 8, 4], [0, 5, 1]], H_value: 8\n",
            "Step 7: [[3, 6, 7], [0, 8, 4], [2, 5, 1]], H_value: 7\n",
            "Step 8: [[0, 6, 7], [3, 8, 4], [2, 5, 1]], H_value: 6\n",
            "Step 9: [[6, 0, 7], [3, 8, 4], [2, 5, 1]], H_value: 5\n",
            "Step 10: [[6, 8, 7], [3, 0, 4], [2, 5, 1]], H_value: 4\n",
            "Step 11: [[6, 8, 7], [3, 5, 4], [2, 0, 1]], H_value: 3\n",
            "Step 12: [[6, 8, 7], [3, 5, 4], [0, 2, 1]], H_value: 2\n",
            "Step 13: [[6, 8, 7], [0, 5, 4], [3, 2, 1]], H_value: 1\n",
            "Step 14: [[0, 8, 7], [6, 5, 4], [3, 2, 1]], H_value: 0\n",
            "Total cost (Pattern Database): 14\n",
            "Số node mở rộng (Pattern Database): 2959\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "A* Search:\n",
            "Initial State: [[3, 6, 7], [4, 8, 2], [5, 0, 1]]\n",
            "Step 1: [[3, 6, 7], [4, 8, 2], [5, 0, 1]], H_value: 11\n",
            "Step 2: [[3, 6, 7], [4, 0, 2], [5, 8, 1]], H_value: 12\n",
            "Step 3: [[3, 6, 7], [0, 2, 4], [5, 8, 1]], H_value: 9\n",
            "Step 4: [[3, 6, 7], [2, 0, 4], [5, 8, 1]], H_value: 10\n",
            "Step 5: [[3, 6, 7], [2, 8, 4], [5, 0, 1]], H_value: 9\n",
            "Step 6: [[3, 6, 7], [2, 8, 4], [0, 5, 1]], H_value: 8\n",
            "Step 7: [[3, 6, 7], [0, 8, 4], [2, 5, 1]], H_value: 7\n",
            "Step 8: [[0, 6, 7], [3, 8, 4], [2, 5, 1]], H_value: 6\n",
            "Step 9: [[6, 0, 7], [3, 8, 4], [2, 5, 1]], H_value: 5\n",
            "Step 10: [[6, 8, 7], [3, 0, 4], [2, 5, 1]], H_value: 4\n",
            "Step 11: [[6, 8, 7], [3, 5, 4], [2, 0, 1]], H_value: 3\n",
            "Step 12: [[6, 8, 7], [3, 5, 4], [0, 2, 1]], H_value: 2\n",
            "Step 13: [[6, 8, 7], [0, 5, 4], [3, 2, 1]], H_value: 3\n",
            "Step 14: [[0, 8, 7], [6, 5, 4], [3, 2, 1]], H_value: 0\n",
            "Total cost (A*): 14\n",
            "Số node mở rộng (A*): 4441\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "BFS Search:\n",
            "Initial State: [[3, 6, 7], [4, 8, 2], [5, 0, 1]]\n",
            "Step 1: [[3, 6, 7], [4, 8, 2], [5, 0, 1]]\n",
            "Step 2: [[3, 6, 7], [4, 0, 2], [5, 8, 1]]\n",
            "Step 3: [[3, 6, 7], [0, 2, 4], [5, 8, 1]]\n",
            "Step 4: [[3, 6, 7], [2, 0, 4], [5, 8, 1]]\n",
            "Step 5: [[3, 6, 7], [2, 8, 4], [5, 0, 1]]\n",
            "Step 6: [[3, 6, 7], [2, 8, 4], [0, 5, 1]]\n",
            "Step 7: [[3, 6, 7], [0, 8, 4], [2, 5, 1]]\n",
            "Step 8: [[0, 6, 7], [3, 8, 4], [2, 5, 1]]\n",
            "Step 9: [[6, 0, 7], [3, 8, 4], [2, 5, 1]]\n",
            "Step 10: [[6, 8, 7], [3, 0, 4], [2, 5, 1]]\n",
            "Step 11: [[6, 8, 7], [3, 5, 4], [2, 0, 1]]\n",
            "Step 12: [[6, 8, 7], [3, 5, 4], [0, 2, 1]]\n",
            "Step 13: [[6, 8, 7], [0, 5, 4], [3, 2, 1]]\n",
            "Step 14: [[0, 8, 7], [6, 5, 4], [3, 2, 1]]\n",
            "Total cost (BFS): 14\n",
            "Số node mở rộng (BFS): 3742\n"
          ]
        }
      ]
    }
  ]
}